{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_amazon = pd.read_csv (\"alexa/amazon_alexa.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 4, 3, 2, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_amazon.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT = string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokenize(entry):\n",
    "    lemmatized = [w.lemma_.lower()  if (w.pos_ != 'PUNCT' and w.lemma_ != '-PRON-') else w.lower_ for w in nlp(entry)]\n",
    "    return [w for w in lemmatized if w not in STOP_WORDS and w not in PUNCT]\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad4d36a371b147a49bd417dfa4a34551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_amazon['tokenized_reviews'] = df_amazon.verified_reviews.progress_apply(clean_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = clean_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function clean_tokenize at 0x10faf3a70>,\n",
       "                use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[w.lemma_.lower()  if (w.pos_ != 'PUNCT' and w.lemma_ != '-PRON-') else w.lower_ for w in rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/54/1d7294672110d5c0565cabc4b99ed952ced9a2dc2ca1d59ad1b34303a6de/gensim-3.8.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (24.7MB)\n",
      "\u001b[K     |████████████████████████████████| 24.7MB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting smart-open>=1.8.1 (from gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/09/735f2786dfac9bbf39d244ce75c0313d27d4962e71e0774750dc809f2395/smart_open-1.9.0.tar.gz (70kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from gensim) (1.17.4)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from gensim) (1.3.1)\n",
      "Collecting boto>=2.32 (from smart-open>=1.8.1->gensim)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 12.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.9.234)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.234 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.245)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.234->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /Users/Tinmar/anaconda3/envs/nlp/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.234->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-1.9.0-cp37-none-any.whl size=73088 sha256=7a720f92ecf1b8dade4f9009a6124f1183ce1bd5361265704fe851832995b403\n",
      "  Stored in directory: /Users/Tinmar/Library/Caches/pip/wheels/ab/10/93/5cff86f5b721d77edaecc29959b1c60d894be1f66d91407d28\n",
      "Successfully built smart-open\n",
      "Installing collected packages: boto, smart-open, gensim\n",
      "Successfully installed boto-2.49.0 gensim-3.8.1 smart-open-1.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
